{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/xwchen/r1-aqa/src\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert AVQA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = \"/home/xwchen/r1-aqa/data/origin/train_qa.json\"\n",
    "with open(original_dataset, 'r') as f:\n",
    "        \n",
    "    conf_json = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "noaudio = []\n",
    "yesaudio = []\n",
    "for cj in conf_json:\n",
    "    audio_path = \"/home/xwchen/data/VGGSound/audio/\" + cj[\"video_name\"] + \".wav\"\n",
    "    if os.path.exists(audio_path):\n",
    "        yesaudio.append(cj[\"video_name\"])\n",
    "        cj[\"dataset_name\"] = \"AVQA\"\n",
    "        cj[\"audio_path\"] = audio_path\n",
    "    else:\n",
    "        noaudio.append(cj[\"video_name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(243, 40182)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(noaudio), len(yesaudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/xwchen/r1-aqa/data/train_qa.jsonl\", 'w') as f:\n",
    "    for cj in conf_json:\n",
    "        if \"audio_path\" in cj.keys():\n",
    "            f.write(json.dumps(cj)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40182\n"
     ]
    }
   ],
   "source": [
    "parsed_dataset = \"/home/xwchen/r1-aqa/data/train_qa.jsonl\"\n",
    "with open(parsed_dataset, 'r') as f:\n",
    "    print(len(f.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"id\": 183, \"video_name\": \"-HG3Omg_89c_000030\", \"video_id\": 341, \"question_text\": \"What happened in the video?\", \"multi_choice\": [\"motorboat\", \"Yacht consignment\", \"Sailboat set sail\", \"Consignment car\"], \"answer\": 1, \"question_relation\": \"View\", \"question_type\": \"Happening\", \"dataset_name\": \"AVQA\", \"audio_path\": \"/home/xwchen/data/VGGSound/audio/-HG3Omg_89c_000030.wav\"}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(conf_json[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.dataset import AudioDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AudioDataset(\"/home/xwchen/r1-aqa/data/train_qa.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 183,\n",
       " 'video_name': '-HG3Omg_89c_000030',\n",
       " 'video_id': 341,\n",
       " 'question_text': 'What happened in the video?',\n",
       " 'multi_choice': ['motorboat',\n",
       "  'Yacht consignment',\n",
       "  'Sailboat set sail',\n",
       "  'Consignment car'],\n",
       " 'answer': 1,\n",
       " 'question_relation': 'View',\n",
       " 'question_type': 'Happening',\n",
       " 'dataset_name': 'AVQA',\n",
       " 'audio_path': '/home/xwchen/data/VGGSound/audio/-HG3Omg_89c_000030.wav',\n",
       " 'audio': array([-0.09594806, -0.161177  , -0.10905909, ..., -0.03818699,\n",
       "        -0.04446336, -0.020881  ], dtype=float32),\n",
       " 'prompt': [{'role': 'user',\n",
       "   'content': [{'type': 'audio',\n",
       "     'audio_url': '/home/xwchen/data/VGGSound/audio/-HG3Omg_89c_000030.wav'},\n",
       "    {'type': 'text',\n",
       "     'text': \"What happened in the audio? Please choose the answer from the following options: ['motorboat', 'Yacht consignment', 'Sailboat set sail', 'Consignment car']. Output the thinking process in <think> </think> and final answer in <answer> </answer>.\"}]}],\n",
       " 'solution': '<answer>Yacht consignment</answer>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "verl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
